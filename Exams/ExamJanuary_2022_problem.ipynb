{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af150ce",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 2021, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "* I (Benny) will visit the exam room at around 10:30 to see if there are any questions.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87c0aa",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"XXX\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0803f8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0b006",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Probability warmup\n",
    "Let's say we have an exam question which consists of $20$ yes/no questions. \n",
    "From past performance of similar students, a randomly chosen student will know the correct answer to $N \\sim \\text{binom}(20,11/20)$ questions. Furthermore, we assume that the student will guess the answer with equal probability to each question they don't know the answer to, i.e. given $N$ we define $Z \\sim \\text{binom}(20-N,1/2)$ as the number of correctly guessed answers. Define $Y = N + Z$, i.e., $Y$ represents the number of total correct answers.\n",
    "\n",
    "We are interested in setting a deterministic threshold $T$, i.e., we would pass a student at threshold $T$ if $Y \\geq T$. Here $T \\in \\{0,1,2,\\ldots,20\\}$.\n",
    "\n",
    "1. [5p] For each threshold $T$, compute the probability that the student *knows* less than $10$ correct answers given that the student passed, i.e., $N < 10$. Put the answer in `problem11_probabilities` as a list.\n",
    "2. [3p] What is the smallest value of $T$ such that if $Y \\geq T$ then we are 90\\% certain that $N \\geq 10$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1990ab",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hint the PMF of N is p_N(k) where p_N is\n",
    "from scipy.special import binom as binomial\n",
    "p = 11/20\n",
    "p_N = lambda k: binomial(20,k)*((1-p)**(20-k))*(p**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21189865",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.24928935982841186),\n",
       " np.float64(0.24928935982832884),\n",
       " np.float64(0.24928935982261047),\n",
       " np.float64(0.24928935963549276),\n",
       " np.float64(0.2492893557683933),\n",
       " np.float64(0.24928929915834963),\n",
       " np.float64(0.2492886751893025),\n",
       " np.float64(0.24928330207958455),\n",
       " np.float64(0.2492462852336602),\n",
       " np.float64(0.24903902630299055),\n",
       " np.float64(0.24808569900431432),\n",
       " np.float64(0.24460820014975931),\n",
       " np.float64(0.2349439695781523),\n",
       " np.float64(0.21475641513175905),\n",
       " np.float64(0.1826713919662099),\n",
       " np.float64(0.14272522447072042),\n",
       " np.float64(0.10227042692681909),\n",
       " np.float64(0.06762809950564572),\n",
       " np.float64(0.04166472439122743),\n",
       " np.float64(0.024151134340423368),\n",
       " np.float64(0.013287462679601604)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Part 1: \n",
    "# replace XXX to represent P(N < 10) for T = [0,1,2,...,20], i.e. your answer should be a list\n",
    "# of length 21.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# PMF of Z | N=n ~ Binom(20-n, 1/2)\n",
    "def p_Z_given_N(z, n):\n",
    "    return binomial(20 - n, z) * (0.5 ** (20 - n))\n",
    "\n",
    "# Compute P(N < 10 | Y >= T) for all T\n",
    "problem11_probabilities = []\n",
    "\n",
    "for T in range(21):\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "    \n",
    "    for n in range(21):\n",
    "        for z in range(21 - n):\n",
    "            y = n + z\n",
    "            prob = p_N(n) * p_Z_given_N(z, n)\n",
    "            \n",
    "            if y >= T:\n",
    "                denominator += prob\n",
    "                if n < 10:\n",
    "                    numerator += prob\n",
    "\n",
    "    problem11_probabilities.append(numerator / denominator)\n",
    "\n",
    "problem11_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbdf94f0",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Part 2: Give an integer between 0 and 20 which is the answer to 2.\n",
    "\n",
    "# Find smallest T such that P(N >= 10 | Y >= T) >= 0.9\n",
    "# i.e. P(N < 10 | Y >= T) <= 0.1\n",
    "\n",
    "problem12_T = next(\n",
    "    T for T, prob in enumerate(problem11_probabilities)\n",
    "    if prob <= 0.1\n",
    ")\n",
    "\n",
    "problem12_T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba061a0a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65bbdf6",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Random variable generation and transformation\n",
    "\n",
    "The purpose of this problem is to show that you can implement your own sampler, this will be built in the following three steps:\n",
    "\n",
    "1. [2p] Implement a Linear Congruential Generator where you tested out a good combination (a large $M$ with $a,b$ satisfying the Hull-Dobell (Thm 6.8)) of parameters. Follow the instructions in the code block.\n",
    "2. [2p] Using a generator construct random numbers from the uniform $[0,1]$ distribution.\n",
    "3. [4p] Using a uniform $[0,1]$ random generator, generate samples from \n",
    "\n",
    "$$p_0(x) = \\frac{\\pi}{2}|\\sin(2\\pi x)|, \\quad x \\in [0,1] \\enspace .$$\n",
    "\n",
    "Using the **Accept-Reject** sampler (**Algorithm 1** in TFDS notes) with sampling density given by the uniform $[0,1]$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3449666b",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem2_LCG(size=None, seed = 0):\n",
    "    \"\"\"\n",
    "    A linear congruential generator that generates pseudo random numbers according to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    seed : the starting point of the LCG, i.e. u0 in the notes.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    out : a list of the pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Linear Congruential Generator producing integers in {0, 1, ..., M-1}\n",
    "    \"\"\"\n",
    "    M = 2147483647\n",
    "    a = 1103515245\n",
    "    b = 12345\n",
    "    \n",
    "    out = []\n",
    "    u = seed\n",
    "    \n",
    "    for _ in range(size):\n",
    "        u = (a * u + b) % M\n",
    "        out.append(u)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7955134",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem2_uniform(generator=None, period = 1, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator and produces samples from the uniform [0,1] distribution according\n",
    "    to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of type generator(size,seed) and produces the same result as problem2_LCG, i.e. pseudo random numbers in the range {0,1,...,period-1}\n",
    "    period : the period of the generator\n",
    "    seed : the seed to be used in the generator provided\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the uniform pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Produces uniform [0,1] samples using an integer-valued generator\n",
    "    \"\"\"\n",
    "    ints = generator(size=size, seed=seed)\n",
    "    out = [x / period for x in ints]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af77a695",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem2_accept_reject(uniformGenerator=None, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator that produces uniform pseudo random [0,1] numbers \n",
    "    and produces samples from (pi/2)*abs(sin(x*2*pi)) using an Accept-Reject\n",
    "    sampler with the uniform distribution as the proposal distribution\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of the type generator(size,seed) that produces uniform pseudo random\n",
    "    numbers from [0,1]\n",
    "    seed : the seed to be used in the generator provided\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the pseudo random numbers with the specified distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Accept-Reject sampler for p0(x) = (pi/2)*|sin(2*pi*x)|\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    current_seed = seed\n",
    "    \n",
    "    while len(out) < size:\n",
    "        # draw two uniforms\n",
    "        u = uniformGenerator(size=2, seed=current_seed)\n",
    "        current_seed += 2\n",
    "        \n",
    "        x = u[0]\n",
    "        y = u[1]\n",
    "        \n",
    "        # accept-reject condition\n",
    "        if y <= abs(np.sin(2 * np.pi * x)):\n",
    "            out.append(x)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599292ac",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32c53dd8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCG output: [1103527590, 944465040, 1695244727, 1008001095, 235077491, 776026401, 964188548, 19180611, 1753372583, 504528511]\n",
      "Uniform sampler [0.5138700783782965, 0.4398008065483537, 0.7894098422440746, 0.46938708772388615, 0.1094664871271078, 0.36136545304272577, 0.44898528067813503, 0.008931668013768115, 0.816477734510078, 0.23493939602511907]\n",
      "Accept-Reject sampler [0.5415987379577005, 0.5970560571165086, 0.6525133762753165, 0.6802420358547205, 0.7079706954341245, 0.7356993550135286, 0.7634280145929325, 0.7911566741723366, 0.8188853337517406, 0.8466139933311445, 0.9020713124899525, 0.0961719295457806, 0.15162924870458863, 0.17935790828399262, 0.20708656786339663, 0.23481522744280064, 0.26254388702220466, 0.29027254660160867, 0.34572986576041664, 0.37345852533982066]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If you managed to solve all three parts you can test the following code to see if it runs\n",
    "# you have to change the period to match your LCG though, this is marked as XXX.\n",
    "# It is a very good idea to check these things using the histogram function in sagemath\n",
    "# try with a larger number of samples, up to 10000 should run\n",
    "\n",
    "print(\"LCG output: %s\" % problem2_LCG(size=10, seed = 1))\n",
    "\n",
    "period = 2147483647\n",
    "\n",
    "print(\"Uniform sampler %s\" % problem2_uniform(generator=problem2_LCG, period = period, size=10, seed=1))\n",
    "\n",
    "uniform_sampler = lambda size,seed: problem2_uniform(generator=problem2_LCG, period = period, size=size, seed=seed)\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem2_accept_reject(uniformGenerator = uniform_sampler,size=20,seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848ffea",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7b29f",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Concentration of measure\n",
    "\n",
    "As you recall, we said that concentration of measure was simply the phenomenon where we expect that the probability of a large deviation of some quantity becoming smaller as we observe more samples: [0.4 points per correct answer]\n",
    "\n",
    "1. Which of the following will exponentially concentrate, i.e. for some $C_1,C_2,C_3,C_4 $ \n",
    "$$\n",
    "    P(Z - \\mathbb{E}[Z] \\geq \\epsilon) \\leq C_1 e^{-C_2 n \\epsilon^2} \\wedge C_3 e^{-C_4 n (\\epsilon+1)} \\enspace .\n",
    "$$\n",
    "\n",
    "    1. The empirical mean of i.i.d. sub-Gaussian random variables?\n",
    "    2. The empirical mean of i.i.d. sub-Exponential random variables?\n",
    "    3. The empirical mean of i.i.d. random variables with finite variance?\n",
    "    4. The empirical variance of i.i.d. random variables with finite variance?\n",
    "    5. The empirical variance of i.i.d. sub-Gaussian random variables?\n",
    "    6. The empirical variance of i.i.d. sub-Exponential random variables?\n",
    "    7. The empirical third moment of i.i.d. sub-Gaussian random variables?\n",
    "    8. The empirical fourth moment of i.i.d. sub-Gaussian random variables?\n",
    "    9. The empirical mean of i.i.d. deterministic random variables?\n",
    "    10. The empirical tenth moment of i.i.d. Bernoulli random variables?\n",
    "\n",
    "2. Which of the above will concentrate in the weaker sense, that for some $C_1$\n",
    "$$\n",
    "    P(Z - \\mathbb{E}[Z] \\geq \\epsilon) \\leq \\frac{C_1}{n \\epsilon^2}?\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d674d70",
   "metadata": {},
   "source": [
    "## Concentration of Measure — First Set (Strict Interpretation)\n",
    "\n",
    "### Key Ideas\n",
    "\n",
    "- **Exponential concentration**: requires strong tail control (sub-Gaussian or sub-Exponential) and independence. Empirical means of sub-Gaussian/sub-Exponential variables and deterministic/bounded quantities can be guaranteed to concentrate exponentially.  \n",
    "- **Polynomial (Chebyshev-type) concentration**: requires only finite variance (or finite variance of the quantity). Deterministic quantities are trivial.\n",
    "\n",
    "We do **not assume anything beyond what is explicitly stated**.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Exponential Concentration\n",
    "\n",
    "Check whether \n",
    "$$P(Z - \\mathbb{E}[Z] \\ge \\epsilon) \\le C_1 e^{-C_2 n \\epsilon^2} \\vee C_3 e^{-C_4 n (\\epsilon+1)}$$\n",
    "applies under the given assumptions.\n",
    "\n",
    "### Item-by-item reasoning\n",
    "\n",
    "1. **Empirical mean of i.i.d. sub-Gaussian random variables**  \n",
    "   Sub-Gaussian assumption guarantees exponential concentration of the mean (Hoeffding inequality).  \n",
    "   ✅ Exponentially concentrates\n",
    "\n",
    "2. **Empirical mean of i.i.d. sub-Exponential random variables**  \n",
    "   Bernstein-type inequalities apply.  \n",
    "   ✅ Exponentially concentrates\n",
    "\n",
    "3. **Empirical mean of i.i.d. random variables with finite variance**  \n",
    "   Finite variance alone does not give exponential tails.  \n",
    "   ❌ Does not exponentially concentrate\n",
    "\n",
    "4. **Empirical variance of i.i.d. sub-Gaussian random variables**  \n",
    "   Quadratic forms of sub-Gaussian RVs concentrate exponentially.  \n",
    "   ✅ Exponentially concentrates\n",
    "\n",
    "5. **Empirical variance of i.i.d. sub-Exponential random variables**  \n",
    "   Sub-Exponential assumption is not sufficient for variance; exponential concentration not guaranteed.  \n",
    "   ❌ Does not exponentially concentrate\n",
    "\n",
    "6. **Empirical variance of i.i.d. random variables with finite variance**  \n",
    "   Finite variance alone is insufficient for exponential concentration.  \n",
    "   ❌ Does not exponentially concentrate\n",
    "\n",
    "7. **Empirical third moment of i.i.d. sub-Gaussian random variables**  \n",
    "   Exponential concentration of higher moments is not guaranteed.  \n",
    "   ❌ Does not exponentially concentrate\n",
    "\n",
    "8. **Empirical fourth moment of i.i.d. sub-Gaussian random variables**  \n",
    "   Same reasoning as above.  \n",
    "   ❌ Does not exponentially concentrate\n",
    "\n",
    "9. **Empirical mean of i.i.d. deterministic random variables**  \n",
    "   Trivial concentration (no randomness).  \n",
    "   ✅ Exponentially concentrates\n",
    "\n",
    "10. **Empirical tenth moment of i.i.d. Bernoulli random variables**  \n",
    "    Bounded → sub-Gaussian → empirical moments concentrate exponentially.  \n",
    "    ✅ Exponentially concentrates\n",
    "\n",
    "### Answer — Exponential Concentration\n",
    "\n",
    "- 1, 2, 4, 9, 10\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Polynomial (Weaker) Concentration\n",
    "\n",
    "Check whether \n",
    "$$P(Z - \\mathbb{E}[Z] \\ge \\epsilon) \\le \\frac{C_1}{n \\epsilon^2}$$\n",
    "applies under the given assumptions.\n",
    "\n",
    "- Sub-Gaussian or sub-Exponential variables have finite variance → polynomial concentration holds: 1,2,4,5,7,8,10  \n",
    "- Finite variance → Chebyshev inequality applies: 3,6  \n",
    "- Deterministic variables trivially satisfy polynomial bound: 9  \n",
    "\n",
    "### Answer — Polynomial Concentration\n",
    "\n",
    "- 1,2,3,4,5,6,7,8,9,10\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| #  | Quantity                                     | Exponential | Polynomial |\n",
    "|----|---------------------------------------------|------------|------------|\n",
    "| 1  | Mean, sub-Gaussian                          | Yes        | Yes        |\n",
    "| 2  | Mean, sub-Exponential                       | Yes        | Yes        |\n",
    "| 3  | Mean, finite variance                        | No         | Yes        |\n",
    "| 4  | Variance, sub-Gaussian                       | Yes        | Yes        |\n",
    "| 5  | Variance, sub-Exponential                    | No         | Yes        |\n",
    "| 6  | Variance, finite variance                    | No         | Yes        |\n",
    "| 7  | 3rd moment, sub-Gaussian                     | No         | Yes        |\n",
    "| 8  | 4th moment, sub-Gaussian                     | No         | Yes        |\n",
    "| 9  | Mean, deterministic                          | Yes        | Yes        |\n",
    "| 10 | 10th moment, Bernoulli                       | Yes        | Yes        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fba5a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Answers to part 1, which of the alternatives exponentially concentrate, answer as a list\n",
    "# i.e. [1,4,5] that is example 1, 4, and 5 concentrate\n",
    "problem3_answer_1 = [1, 2, 4, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11def9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Answers to part 2, which of the alternatives concentrate in the weaker sense, answer as a list\n",
    "# i.e. [1,4,5] that is example 1, 4, and 5 concentrate\n",
    "problem3_answer_2 = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876a583",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 4\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6266e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## SMS spam filtering [8p]\n",
    "\n",
    "In the following problem we will explore SMS spam texts. The dataset is the `SMS Spam Collection Dataset` and we have provided for you a way to load the data. If you run the appropriate cell below, the result will be in the `spam_no_spam` variable. The result is a `list` of `tuples` with the first position in the tuple being the SMS text and the second being a flag `0 = not spam` and `1 = spam`.\n",
    "\n",
    "1. [3p] Let $X$ be the random variable that represents each SMS text (an entry in the list), and let $Y$ represent whether text is spam or not i.e. $Y \\in \\{0,1\\}$. Thus $\\mathbb{P}(Y = 1)$ is the probability that we get a spam. The goal is to estimate:\n",
    "$$\n",
    "    \\mathbb{P}(Y = 1 | \\text{\"free\" or \"prize\" is in } X) \\enspace .\n",
    "$$\n",
    "That is, the probability that the SMS is spam given that \"free\" or \"prize\" occurs in the SMS. \n",
    "Hint: it is good to remove the upper/lower case of words so that we can also find \"Free\" and \"Prize\"; this can be done with `text.lower()` if `text` a string.\n",
    "2. [3p] Provide a \"90\\%\" interval of confidence around the true probability. I.e. use the Hoeffding inequality to obtain for your estimate $\\hat P$ of the above quantity. Find $l > 0$ such that the following holds:\n",
    "$$\n",
    "    \\mathbb{P}(\\hat P - l \\leq \\mathbb{E}[\\hat P] \\leq \\hat P + l) \\geq 0.9 \\enspace .\n",
    "$$\n",
    "3. [2p] Repeat the two exercises above for \"free\" appearing twice in the SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86b4ce",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run this cell to get the SMS text data\n",
    "from exam_extras import load_sms\n",
    "spam_no_spam = load_sms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0f279",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill in the estimate for part 1 here (should be a number between 0 and 1)\n",
    "\n",
    "# ---------- Part 1: \"free\" OR \"prize\" appears ----------\n",
    "labels_1 = []\n",
    "for text, y in spam_no_spam:\n",
    "    t = text.lower()\n",
    "    if (\"free\" in t) or (\"prize\" in t):\n",
    "        labels_1.append(y)\n",
    "\n",
    "n1 = len(labels_1)\n",
    "problem4_hatP = sum(labels_1) / n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72cc4e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill in the calculated l from part 2 here\n",
    "\n",
    "import math\n",
    "\n",
    "# Hoeffding bound with delta = 0.1 (90% confidence)\n",
    "delta = 0.1\n",
    "problem4_l = math.sqrt((1 / (2 * n1)) * math.log(2 / delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100e5ea",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill in the estimate for hatP for the double free question in part 3 here (should be a number between 0 and 1)\n",
    "\n",
    "# ---------- Part 3: \"free\" appears at least twice ----------\n",
    "labels_2 = []\n",
    "for text, y in spam_no_spam:\n",
    "    t = text.lower()\n",
    "    if t.count(\"free\") >= 2:\n",
    "        labels_2.append(y)\n",
    "\n",
    "n2 = len(labels_2)\n",
    "problem4_hatP2 = sum(labels_2) / n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19289d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill in the estimate for l for the double free question in part 3 here\n",
    "\n",
    "problem4_l2 = math.sqrt((1 / (2 * n2)) * math.log(2 / delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87be90d",
   "metadata": {},
   "source": [
    "### What this does (brief explanation)\n",
    "\n",
    "- **Estimator**\n",
    "\n",
    "  \n",
    "  $$\\hat P = \\frac{\\text{\\# spam messages satisfying condition}}{\\text{\\# messages satisfying condition}}$$\n",
    "  \n",
    "\n",
    "- **Hoeffding bound (Bernoulli variables)**  \n",
    "  For confidence level $1 - \\delta = 0.9$:\n",
    "\n",
    "  \n",
    "  $$l = \\sqrt{\\frac{1}{2n}\\ln\\left(\\frac{2}{\\delta}\\right)}$$\n",
    " \n",
    "\n",
    "- **Uses:**\n",
    "  - Case-insensitive matching (`text.lower()`)\n",
    "  - Substring counting for `\"free\"` appearing twice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7d777",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 5\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e686c",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Markovian travel\n",
    "\n",
    "The dataset `Travel Dataset - Datathon 2019` is a simulated dataset designed to mimic real corporate travel systems -- focusing on flights and hotels. The file is at `data/flights.csv` in the same folder as `Exam.ipynb`, i.e. you can use the path `data/flights.csv` from the notebook to access the file.\n",
    "\n",
    "1. [2p] In the first code-box \n",
    "    1. Load the csv from file `data/flights.csv`\n",
    "    2. Fill in the value of the variables as specified by their names.\n",
    "2. [2p] In the second code-box your goal is to estimate a Markov chain transition matrix for the travels of these users. For example, if we enumerate the cities according to alphabetical order, the first city `'Aracaju (SE)'` would correspond to $0$. Each row of the file corresponds to one flight, i.e. it has a starting city and an ending city. We model this as a stationary Markov chain, i.e. each user's travel trajectory is a realization of the Markov chain, $X_t$. Here, $X_t$ is the current city the user is at, at step $t$, and $X_{t+1}$ is the city the user travels to at the next time step. This means that to each row in the file there is a corresponding pair $(X_{t},X_{t+1})$. The stationarity assumption gives that for all $t$ there is a transition density $p$ such that $P(X_{t+1} = y | X_t = x) = p(x,y)$ (for all $x,y$). The transition matrix should be `n_cities` x `n_citites` in size.\n",
    "3. [2p] Use the transition matrix to compute out the stationary distribution.\n",
    "4. [2p] Given that we start in 'Aracaju (SE)' what is the probability that after 3 steps we will be back in 'Aracaju (SE)'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae50be9c",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/flights.csv\")\n",
    "\n",
    "# Basic quantities\n",
    "number_of_cities = df[\"from\"].nunique()\n",
    "number_of_userCodes = df[\"userCode\"].nunique()\n",
    "number_of_observations = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b2cd78",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This is a very useful function that you can use for part 2. You have seen this before when parsing the\n",
    "# pride and prejudice book.\n",
    "\n",
    "def makeFreqDict(myDataList):\n",
    "    '''Make a frequency mapping out of a list of data.\n",
    "\n",
    "    Param myDataList, a list of data.\n",
    "    Return a dictionary mapping each unique data value to its frequency count.'''\n",
    "\n",
    "    freqDict = {} # start with an empty dictionary\n",
    "\n",
    "    for res in myDataList:\n",
    "        if res in freqDict: # the data value already exists as a key\n",
    "                freqDict[res] = freqDict[res] + 1 # add 1 to the count using sage integers\n",
    "        else: # the data value does not exist as a key value\n",
    "            freqDict[res] = 1 # add a new key-value pair for this new data value, frequency 1\n",
    "\n",
    "    return freqDict # return the dictionary created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddfee1fd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Collect all cities appearing as origins\n",
    "cities = list(df[\"from\"])\n",
    "\n",
    "unique_cities = sorted(set(cities)) # The unique cities\n",
    "n_cities = len(unique_cities) # The number of unique citites\n",
    "\n",
    "# Count the different transitions\n",
    "\n",
    "# Build transition list (X_t, X_{t+1})\n",
    "transitions = list(zip(df[\"from\"], df[\"to\"])) # A list containing tuples ex: ('Aracaju (SE)','Rio de Janeiro (RJ)') of all transitions in the text\n",
    "\n",
    "# Count transitions\n",
    "transition_counts = makeFreqDict(transitions) # A dictionary that counts the number of each transition \n",
    "\n",
    "# ex: ('Aracaju (SE)','Rio de Janeiro (RJ)'):4\n",
    "indexToCity = {i: city for i, city in enumerate(unique_cities)} # A dictionary that maps the n-1 number to the n:th unique_city,\n",
    "# ex: 0:'Aracaju (SE)'\n",
    "cityToIndex = {city: i for i, city in indexToCity.items()} # The inverse function of indexToWord, \n",
    "# ex: 'Aracaju (SE)':0\n",
    "\n",
    "# Part 3, finding the maximum likelihood estimate of the transition matrix\n",
    "\n",
    "# Initialize transition matrix\n",
    "transition_matrix = np.zeros((n_cities, n_cities)) # a numpy array of size (n_cities,n_cities)\n",
    "\n",
    "# Count outgoing transitions per city\n",
    "outgoing_counts = makeFreqDict(df[\"from\"])\n",
    "\n",
    "# The transition matrix should be ordered in such a way that\n",
    "# p_{'Aracaju (SE)','Rio de Janeiro (RJ)'} = transition_matrix[cityToIndex['Aracaju (SE)'],cityToIndex['Rio de Janeiro (RJ)']]\n",
    "# and represents the probability of travelling Aracaju (SE)->Rio de Janeiro (RJ)\n",
    "\n",
    "# Fill transition matrix with MLE probabilities\n",
    "for (city_from, city_to), count in transition_counts.items():\n",
    "    i = cityToIndex[city_from]\n",
    "    j = cityToIndex[city_to]\n",
    "    transition_matrix[i, j] = count / outgoing_counts[city_from]\n",
    "\n",
    "# Make sure that the transition_matrix does not contain np.nan from division by zero for instance\n",
    "\n",
    "# Ensure no NaNs\n",
    "transition_matrix = np.nan_to_num(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2053f5d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This should be a numpy array of length n_cities which sums to 1 and is all positive\n",
    "\n",
    "# Eigenvector method\n",
    "eigvals, eigvecs = np.linalg.eig(transition_matrix.T)\n",
    "\n",
    "# Find eigenvector corresponding to eigenvalue 1\n",
    "idx = np.argmin(np.abs(eigvals - 1))\n",
    "stationary = np.real(eigvecs[:, idx])\n",
    "\n",
    "# Normalize\n",
    "stationary_distribution_problem5 = stationary / stationary.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b10afd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute the return probability for part 3 of problem 5\n",
    "\n",
    "P3 = np.linalg.matrix_power(transition_matrix, 3)\n",
    "\n",
    "aracaju_index = cityToIndex['Aracaju (SE)']\n",
    "\n",
    "return_probability_problem5 = P3[aracaju_index, aracaju_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31083a19",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 5\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c51e7c9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aracaju (SE)->Recife (PE)->Campo Grande (MS)->Sao Paulo (SP)->Salvador (BH)->Natal (RN)->Recife (PE)->Florianopolis (SC)->Sao Paulo (SP)->Natal (RN)->"
     ]
    }
   ],
   "source": [
    "# Once you have created all your functions, you can make a small test here to see\n",
    "# what would be generated from your model.\n",
    "import numpy as np\n",
    "\n",
    "start = np.zeros(shape=(n_cities,1))\n",
    "start[cityToIndex['Aracaju (SE)'],0] = 1\n",
    "\n",
    "current_pos = start\n",
    "for i in range(10):\n",
    "    random_word_index = np.random.choice(range(n_cities),p=current_pos.reshape(-1))\n",
    "    current_pos = np.zeros_like(start)\n",
    "    current_pos[random_word_index] = 1\n",
    "    print(indexToCity[random_word_index],end='->')\n",
    "    current_pos = (current_pos.T@transition_matrix).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d372c",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 6\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4571e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Black box testing\n",
    "\n",
    "In the following problem we will continue with our SMS spam / nospam data. This time we will try to approach the problem as a pattern recognition problem. For this particular problem I have provided you with everything -- data is prepared, split into train-test sets and a black-box model has been fitted on the training data and predicted on the test data. Your goal is to calculate test metrics and provide guarantees for each metric.\n",
    "\n",
    "1. [2p] Compute precision for class 1 (see notes 8.3.2 for definition), then provide an interval using Hoeffding's inequality for a 95\\% confidence.\n",
    "2. [2p] Compute recall for class 1(see notes 8.3.2 for definition), then provide an interval using Hoeffding's inequality for a 95\\% interval.\n",
    "3. [2p] Compute accuracy (0-1 loss), then provide an interval using Hoeffding's inequality for a 95\\% interval.\n",
    "4. [2p] If we would have used a classifier with VC-dimension 3, would we have obtained a smaller interval for accuracy by using all data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8148a9",
   "metadata": {
    "deletable": false,
    "jupyter": {
     "source_hidden": false
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# The code below will load data, split the data into train and test and run a \"black box\" algorithm on it\n",
    "# the result of the \"black box\" is stored in predictions_problem6, the true values will be stored in\n",
    "# Y_test_problem6\n",
    "import exam_extras\n",
    "from exam_extras import load_sms_problem6\n",
    "X_problem6, Y_problem6 = load_sms_problem6()\n",
    "\n",
    "X_train_problem6,X_test_problem6,Y_train_problem6,Y_test_problem6 = exam_extras.train_test_split(X_problem6,Y_problem6)\n",
    "predictions_problem6 = exam_extras.knn_predictions(X_train_problem6,Y_train_problem6,X_test_problem6,k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f59dcd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Compute the precision of predictions_problem6 with respect to Y_test_problem6\n",
    "\n",
    "pred = np.array(predictions_problem6)\n",
    "true = np.array(Y_test_problem6)\n",
    "\n",
    "# Precision for class 1\n",
    "tp = np.sum((pred == 1) & (true == 1))\n",
    "fp = np.sum((pred == 1) & (true == 0))\n",
    "\n",
    "problem6_precision = tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737fd58",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute the interval length l of precision of predictions_problem6 with respect to Y_test_problem6, with the same definition of l as in problem 4\n",
    "\n",
    "# Hoeffding interval (95%)\n",
    "delta = 0.05\n",
    "n_precision = tp + fp\n",
    "problem6_precision_l = math.sqrt((1 / (2 * n_precision)) * math.log(2 / delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb2ebc",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Repeat the same procedure but for recall\n",
    "\n",
    "fn = np.sum((pred == 0) & (true == 1))\n",
    "\n",
    "problem6_recall = tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b6f78",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "n_recall = tp + fn\n",
    "problem6_recall_l = math.sqrt((1 / (2 * n_recall)) * math.log(2 / delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ade7dd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Repeat the same procedure but for accuracy or 0-1 loss\n",
    "\n",
    "correct = np.sum(pred == true)\n",
    "n_test = len(true)\n",
    "\n",
    "problem6_accuracy = correct / n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e2b11",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "problem6_accuracy_l = math.sqrt((1 / (2 * n_test)) * math.log(2 / delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df926281",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Below you will calculate the interval parameter l for a classifier running on all data with a VC dimension of 3\n",
    "# put the value in problem6_VC_l and answer problem_VC_smaller as True if the interval is smaller than the test-accuracy above\n",
    "# if not answer False. Make sure you replace XXX with something even if you only answer one of them.\n",
    "# VC-dimension bound\n",
    "\n",
    "d = 3\n",
    "n_all = len(Y_problem6)\n",
    "\n",
    "problem6_VC_l = math.sqrt(\n",
    "    (8 / n_all) * (math.log(4 / delta) + d * math.log((2 * math.e * n_all) / d))\n",
    ")\n",
    "\n",
    "# Is the VC interval smaller than the test Hoeffding interval?\n",
    "problem6_VC_smaller = problem6_VC_l < problem6_accuracy_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f8ef9",
   "metadata": {},
   "source": [
    "## Part 1 — Precision (class 1) with 95% Hoeffding interval\n",
    "\n",
    "### Definition\n",
    "\n",
    "Precision for class 1 is defined as\n",
    "\n",
    "$$\n",
    "\\text{Precision} = P(Y = 1 \\mid \\hat Y = 1)\n",
    "$$\n",
    "\n",
    "That is, among all samples predicted as spam, how many are actually spam.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2 — Recall (class 1) with 95% Hoeffding interval\n",
    "\n",
    "### Definition\n",
    "\n",
    "Recall for class 1 is defined as\n",
    "\n",
    "$$\n",
    "\\text{Recall} = P(\\hat Y = 1 \\mid Y = 1)\n",
    "$$\n",
    "\n",
    "That is, among all true spam messages, how many are correctly identified as spam by the classifier.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3 — Accuracy (0–1 loss) with 95% Hoeffding interval\n",
    "\n",
    "### Definition\n",
    "\n",
    "Accuracy (also called 0–1 accuracy) is defined as the fraction of correct predictions:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\{\\hat Y_i = Y_i\\}\n",
    "$$\n",
    "\n",
    "This measures the overall probability that the classifier predicts the correct label.\n",
    "\n",
    "---\n",
    "\n",
    "## Confidence intervals via Hoeffding’s inequality\n",
    "\n",
    "For a bounded random variable $X \\in [0,1]$ and $n$ independent samples, Hoeffding’s inequality gives\n",
    "\n",
    "$$\n",
    "P\\left( |\\hat{P} - \\mathbb{E}[\\hat{P}]| \\le l \\right) \\ge 1 - \\delta\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "l = \\sqrt{\\frac{1}{2n} \\ln\\left(\\frac{2}{\\delta}\\right)}\n",
    "$$\n",
    "\n",
    "This bound is distribution-free and holds for precision, recall, and accuracy since they are averages of Bernoulli random variables.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4 — VC-dimension bound comparison\n",
    "\n",
    "### VC generalization bound\n",
    "\n",
    "For a hypothesis class with VC-dimension $d$, a standard uniform convergence bound for accuracy is\n",
    "\n",
    "$$\n",
    "l_{\\text{VC}} =\n",
    "\\sqrt{\n",
    "\\frac{8}{n}\n",
    "\\left(\n",
    "\\log\\frac{4}{\\delta}\n",
    "+ d \\log\\frac{2 e n}{d}\n",
    "\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "This bound holds uniformly over the entire hypothesis class and does not depend on the observed labels.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- VC-dimension bounds are **distribution-free**, making them more conservative.\n",
    "- Hoeffding bounds computed on a test set are typically **tighter**.\n",
    "- Even when using all data, a low-VC classifier does **not necessarily** yield a smaller confidence interval than a test-based Hoeffding bound.\n",
    "\n",
    "---\n",
    "\n",
    "## Final conclusion\n",
    "\n",
    "Using a classifier with VC-dimension 3 on all available data would **not generally produce a smaller confidence interval** for accuracy compared to the Hoeffding interval computed on the test set.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2022",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
