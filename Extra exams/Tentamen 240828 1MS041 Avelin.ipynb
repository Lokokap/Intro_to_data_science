{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f67069c",
   "metadata": {},
   "source": [
    "1.6 Exam vB, PROBLEM 1\n",
    "Maximum Points = 14\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using\n",
    "your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in\n",
    "mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "1. [4p] Fill in the remaining part of the function problem1_rejection in order to produce samples\n",
    "from the below density using rejection sampling: $$f[x] = C(sin(x))^{10}$$ for 0 ≤ x ≤ π, where C is a value such that f above is a density (i.e. integrates to one). Hint: you do not need to know the value of C to perform rejection sampling.\n",
    "2. [2p] Produce 10000 samples (use fewer if it takes too long) and put the answer in\n",
    "problem1_samples from the above distribution and plot the histogram.\n",
    "3. [2p] Define X as a random variable with the density given in part 1. Denote $Y = (X - \\frac{\\pi}{2})^2$\n",
    "and use the above 10000 samples to estimate $$E[Y]$$ and store the result in problem1_expectation.\n",
    "4. [2p] Use Hoeffdings inequality to produce a 95% confidence interval of the expectation above\n",
    "and store the result as a tuple in the variable problem1_interval\n",
    "5. [4p] Can you calculate an approximation of the value of C from part 1 using random samples?\n",
    "Provide a plot of the histogram from part 2 together with the true density as a curve, recall\n",
    "that this requires the value of C. Explain what method you used and what answer you got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51949697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "#def problem1_rejection(n_samples=1):\n",
    "# Distribution from part 1\n",
    "# write the code in this function to produce samples from the distribution\n",
    "# in the assignment\n",
    "# Return a numpy array of length n_samples\n",
    "#    return XXX\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def problem1_rejection(n_samples=1):\n",
    "    samples = []\n",
    "    while len(samples) < n_samples:\n",
    "        x = np.random.uniform(0, np.pi)  # proposal sample\n",
    "        u = np.random.uniform(0, 1)      # uniform for acceptance\n",
    "        if u <= np.sin(x)**10:            # accept/reject\n",
    "            samples.append(x)\n",
    "    return np.array(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Part 2\n",
    "problem1_samples = problem1_rejection(10000)\n",
    "\n",
    "plt.hist(problem1_samples, bins=50, density=True, alpha=0.6, color='skyblue')\n",
    "plt.title(\"Histogram of Samples from f(x) = (sin x)^10\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "# Part 3\n",
    "Y = (problem1_samples - np.pi/2)**2\n",
    "problem1_expectation = np.mean(Y)\n",
    "problem1_expectation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "problem1_interval = [XXX,XXX]n = len(problem1_samples)\n",
    "a, b = 0, (np.pi/2)**2\n",
    "epsilon = np.sqrt((b-a)**2 * np.log(2/0.05) / (2*n))  # 95% confidence\n",
    "\n",
    "problem1_interval = (problem1_expectation - epsilon, problem1_expectation + epsilon)\n",
    "problem1_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775883e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "U = np.random.uniform(0, np.pi, 100000)\n",
    "integral_estimate = np.pi * np.mean(np.sin(U)**10)\n",
    "problem1_C = 1 / integral_estimate\n",
    "problem1_C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b328a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "# Write your code to produce the plot here\n",
    "#XXXXXXX\n",
    "\n",
    "x_vals = np.linspace(0, np.pi, 500)\n",
    "f_true = problem1_C * (np.sin(x_vals)**10)\n",
    "\n",
    "plt.hist(problem1_samples, bins=50, density=True, alpha=0.6, color='skyblue', label='Samples')\n",
    "plt.plot(x_vals, f_true, color='red', lw=2, label='True density')\n",
    "plt.title(\"Histogram with True Density\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c26b05",
   "metadata": {},
   "source": [
    "2 Part 5\n",
    "Double click this cell and directly edit below to answer part 5\n",
    "\n",
    "### 2.0.1 Explanation\n",
    "\n",
    "1. **Rejection sampling**: We used a uniform proposal and accepted \\(x\\) with probability \\((\\sin x)^{10}\\). This allows us to generate samples from the target density without knowing the normalization constant \\(C\\).\n",
    "\n",
    "2. **Monte Carlo integration**: The expectation \\(E[Y]\\) was estimated using the sample mean of \n",
    "\\[\n",
    "Y = (X - \\pi/2)^2\n",
    "\\]\n",
    "over the samples obtained from the rejection sampling.\n",
    "\n",
    "3. **Confidence interval**: Hoeffding's inequality was applied using the known bounds of \\(Y\\) (0 and \\((\\pi/2)^2\\)) to produce a 95% confidence interval.\n",
    "\n",
    "4. **Estimating \\(C\\)**: We sampled uniformly over \\([0, \\pi]\\), averaged \\((\\sin x)^{10}\\) over these samples, multiplied by \\(\\pi\\) to estimate the integral\n",
    "\\[\n",
    "\\int_0^\\pi (\\sin x)^{10} dx\n",
    "\\]\n",
    "and then inverted it to obtain the estimate of \\(C\\).\n",
    "\n",
    "This method works because Monte Carlo integration provides a simple numerical approximation of \n",
    "\\[\n",
    "\\int_0^\\pi (\\sin x)^{10} dx\n",
    "\\] \n",
    "without requiring an analytic solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2686b1",
   "metadata": {},
   "source": [
    "2.1 Exam vB, PROBLEM 2\n",
    "Maximum Points = 13\n",
    "Consider the dataset CORIS.csv that you find in the data folder. The data set CORIS.csv contains\n",
    "cases of coronary heart disease (CHD) and variables associated with the patient’s condition: systolic\n",
    "blood pressure, yearly tobacco use (in kg), low density lipoprotein (Idl), adiposity, family history\n",
    "(0 or 1), type A personality score (typea), obesity (body mass index), alcohol use, age, and the\n",
    "diagnosis of CHD (0 or 1). In this dataset the X corresponds to the measurements. The Y is a 0-1\n",
    "label where 1 represents CHD and 0 does not. The code to load the data is prepared and so is the\n",
    "train-test-validation split and the training of the model. The model is stored in problem2_pipe\n",
    "which is a Pipeline object as often used in composite models in sklearn, you will find in the cell\n",
    "corresponding to the different parts, some sample code how to use the model.\n",
    "1. [3p] Use Hoeffdings inequality and compute the intervals for precision-recall etc. on the test\n",
    "set with 95% confidence.\n",
    "2. [3p] You are interested in minimizing the average cost of your classifier. The hospital wants\n",
    "to use your model as a screening tool, that is, if it finds that someone is classified as CHD we\n",
    "interpret this as further investigation needs to take place, otherwise we do noting. After some\n",
    "deliberations you come to the conclusion that the following “costs” should be used (note, this\n",
    "is all imaginary at this point),\n",
    "\n",
    "• If someone has coronary heart disease but classified as not, we say it costs 300 (this is\n",
    "the worst scenario)\n",
    "\n",
    "• If someone does not have coronary heart disease but classified as having it, we say it\n",
    "costs 10 (this is less bad than the above issue)\n",
    "\n",
    "• If someone has coronary heart disease but classified as having it, costs 0 (We did the\n",
    "right thing, no cost)\n",
    "\n",
    "• If someone does not have coronary heart disease but classified as not, costs 0 (We did\n",
    "the right thing, no cost).\n",
    "\n",
    "complete filling the function cost to compute the cost of a prediction model under a certain prediction threshold (recall our precision recall lecture and the predict_proba function from the LogisticRegression (code provided)).\n",
    "\n",
    "3. [4p] Now, we wish to select the threshold of our classifier that minimizes the cost, we do\n",
    "that by checking say 100 evenly spaced proposal thresholds between 0 and 1. Compute the\n",
    "optimal threshold using the testing data and calculate the cost at the chosen threshold using\n",
    "the testing data.\n",
    "\n",
    "4. [3p] With your newly computed threshold value, compute the cost of putting this model in\n",
    "production by computing the cost using the validation data. Also provide a confidence interval\n",
    "of the cost using Hoeffdings inequality with a 99% confidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ab7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "CORISDataset = pd.read_csv(\"data/CORIS.csv\",skiprows=[1,2])\n",
    "# Initial data split into features and target\n",
    "problem2_X = CORISDataset[['sbp','tobacco','ldl','adiposity','famhist','typea','obesity','alcohol','age']].values # Features\n",
    "problem2_Y = CORISDataset['chd'].values # Target variable\n",
    "# Split the data into training, test and validation sets\n",
    "problem2_X_train, X_tmp, problem2_Y_train, Y_tmp = train_test_split(problem2_X,problem2_Y,train_size=0.6,random_state=42)\n",
    "problem2_X_test, problem2_X_val, problem2_Y_test, problem2_Y_val = train_test_split(X_tmp,Y_tmp,train_size=0.5,random_state=42)\n",
    "# Show the shapes of the data\n",
    "print(problem2_X_train.shape,problem2_Y_train.shape, problem2_X_test.shape, problem2_Y_test.shape, problem2_X_val.shape, problem2_Y_val.shape)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create a pipeline with a scaler and a logistic regression model\n",
    "problem2_pipe = Pipeline([('scaler',StandardScaler()),('logreg',LogisticRegression(random_state=42))])\n",
    "# Fit the pipeline to the training data\n",
    "problem2_pipe.fit(problem2_X_train,problem2_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# To make a prediction on a dataset `X` you can use the following code\n",
    "# predictions = problem2_pipe.predict(X)\n",
    "# That is, as with any other sklearn model, you can use the `predict` method\n",
    "# Each precision and recall should be a tuple, for instance you can write\n",
    "# precision0 = (0.9,0.95)\n",
    "# the 0 or 1 in the variable name indicates the class\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def hoeffding_interval(p_hat, n, delta=0.05):\n",
    "    eps = np.sqrt(np.log(2/delta)/(2*n))\n",
    "    return (max(0, p_hat - eps), min(1, p_hat + eps))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = problem2_pipe.predict(problem2_X_test)\n",
    "y_true_test = problem2_Y_test\n",
    "\n",
    "# Compute precision and recall for both classes\n",
    "precision0_hat = precision_score(y_true_test, y_pred_test, pos_label=0)\n",
    "precision1_hat = precision_score(y_true_test, y_pred_test, pos_label=1)\n",
    "recall0_hat = recall_score(y_true_test, y_pred_test, pos_label=0)\n",
    "recall1_hat = recall_score(y_true_test, y_pred_test, pos_label=1)\n",
    "\n",
    "# Number of samples in each class\n",
    "n0 = sum(y_true_test == 0)\n",
    "n1 = sum(y_true_test == 1)\n",
    "\n",
    "# Hoeffding intervals\n",
    "problem2_precision0 = hoeffding_interval(precision0_hat, n0)\n",
    "problem2_precision1 = hoeffding_interval(precision1_hat, n1)\n",
    "problem2_recall0 = hoeffding_interval(recall0_hat, n0)\n",
    "problem2_recall1 = hoeffding_interval(recall1_hat, n1)\n",
    "\n",
    "# The code below will check that you supply the proper type\n",
    "assert(type(problem2_precision0) == tuple)\n",
    "assert(len(problem2_precision0) == 2)\n",
    "assert(type(problem2_recall0) == tuple)\n",
    "assert(len(problem2_recall0) == 2)\n",
    "assert(type(problem2_precision1) == tuple)\n",
    "assert(len(problem2_precision1) == 2)\n",
    "assert(type(problem2_recall1) == tuple)\n",
    "assert(len(problem2_recall1) == 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "#def problem2_cost(model,threshold,X,Y):\n",
    "#    pred_proba = model.predict_proba(X)[:,1]\n",
    "#    predictions = (pred_proba >= threshold).astype(int)\n",
    "    # Fill in what is missing to compute the cost and return it\n",
    "    # Note that we are interested in average cost (cost per person)\n",
    "#    return XXX\n",
    "\n",
    "def problem2_cost(model, threshold, X, Y):\n",
    "    pred_proba = model.predict_proba(X)[:,1]\n",
    "    predictions = (pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    cost = np.where((Y==1) & (predictions==0), 300, 0)  # FN cost\n",
    "    cost += np.where((Y==0) & (predictions==1), 10, 0)  # FP cost\n",
    "    avg_cost = np.mean(cost)\n",
    "    return avg_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af314395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "costs = [problem2_cost(problem2_pipe, t, problem2_X_test, problem2_Y_test) for t in thresholds]\n",
    "\n",
    "min_idx = np.argmin(costs)\n",
    "problem2_optimal_threshold = thresholds[min_idx]\n",
    "problem2_cost_at_optimal_threshold = costs[min_idx]\n",
    "\n",
    "problem2_optimal_threshold, problem2_cost_at_optimal_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Cost on validation data\n",
    "problem2_cost_at_optimal_threshold_validation = problem2_cost(problem2_pipe, problem2_optimal_threshold, problem2_X_val, problem2_Y_val)\n",
    "\n",
    "# Hoeffding interval (99% confidence)\n",
    "n_val = len(problem2_Y_val)\n",
    "delta = 0.01\n",
    "eps = np.sqrt(np.log(2/delta)/(2*n_val))\n",
    "problem2_cost_interval = (max(0, problem2_cost_at_optimal_threshold_validation - eps),\n",
    "                          min(1, problem2_cost_at_optimal_threshold_validation + eps))\n",
    "\n",
    "# The code below will tell you if you filled in the intervals correctly\n",
    "assert(type(problem2_cost_interval) == tuple)\n",
    "assert(len(problem2_cost_interval) == 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf9e7d",
   "metadata": {},
   "source": [
    "2.2 Exam vB, PROBLEM 3\n",
    "Maximum Points = 13\n",
    "Consider the following two Markov chains:\n",
    "\n",
    "Markov Chain A: A to D: 0.8, D to C: 0.5, C to B: 1, B to A: 0, A to B: 0.2, B to C: 1, C to D 0, D to A: 0.5\n",
    "\n",
    "Markov Chain B: A to B: 1, B to C 1, C to B: 0.5, C to D: 0.5, D to C: 0.5, D to E: 0.5, E to F: 1, F to E: 0.5, F to A: 0.5\n",
    "\n",
    "Answer each question for all chains:\n",
    "1. [2p] What is the transition matrix?\n",
    "2. [1p] Is the Markov chain irreducible?\n",
    "3. [4p] Is the Markov chain aperiodic? What is the period for each state? Hint: Recall our definition\n",
    "of period; Let\n",
    "4. [2p] Being in state A at time 0 what is the probability of being in state B at time 5 (after 5 steps)\n",
    "5. [4p] Define T as the first time being in state D starting in state A. That is, if X0, X1, . . . is the\n",
    "Markov chain then define for X0 = ”A”\n",
    "$$T(ω) = inf_{t∈N} \\{t : X_t(ω) = ”D”\\}$$\n",
    "where the infimum over the empty set is ∞. Calculate P(T = 1), P(T = 2), P(T = 3),\n",
    "P(T = 4), P(T = 5), P(T = ∞)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1\n",
    "#------------------------TRANSITION MATRIX -------------------------------\n",
    "# Answer each one by supplying the transition matrix as a numpy array\n",
    "# of shape (n_states,n_states), where state (A,B,...) corresponds to index (0,1,...)\n",
    "import numpy as np\n",
    "\n",
    "problem3_A = np.array([[0,0.2,0,0.8],\n",
    "                       [0,0,1,0],\n",
    "                       [0,1,0,0],\n",
    "                       [0.5,0,0.5,0]])\n",
    "\n",
    "problem3_B = np.array([[0,1,0,0,0,0],\n",
    "                       [0,0,1,0,0,0],\n",
    "                       [0,0.5,0,0.5,0,0],\n",
    "                       [0,0,0.5,0,0.5,0],\n",
    "                       [0,0,0,0,0,1],\n",
    "                       [0.5,0,0,0,0.5,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2\n",
    "#------------------------REDUCIBLE -------------------------------\n",
    "# Answer each one with a True or False\n",
    "problem3_A_irreducible = True\n",
    "problem3_B_irreducible = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c85c46",
   "metadata": {},
   "outputs": [],
   "source": [
    " # PART 3\n",
    "#------------------------APERIODIC-------------------------------\n",
    "# Answer each one with a True or False\n",
    "problem3_A_is_aperiodic = True\n",
    "problem3_B_is_aperiodic = False\n",
    "\n",
    "problem3_A_periods = np.array([1,1,1,1])\n",
    "problem3_B_periods = np.array([4,2,2,2,2,2])  # approximate calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4\n",
    "# Answer the following with the probability of being in state B at time 5 for the two problems\n",
    "problem3_A_PB5 = np.linalg.matrix_power(problem3_A,5)[0,1]\n",
    "problem3_B_PB5 = np.linalg.matrix_power(problem3_B,5)[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84423ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 5\n",
    "# Answer the following probabilities for T=1,2,3,4,5 and infinity\n",
    "problem3_A_PT1 = 0.8\n",
    "problem3_A_PT2 = 0\n",
    "problem3_A_PT3 = 0\n",
    "problem3_A_PT4 = 0\n",
    "problem3_A_PT5 = 0\n",
    "problem3_A_PT_inf = 0.2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
