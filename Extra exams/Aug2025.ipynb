{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec6a472",
   "metadata": {},
   "source": [
    "1.6 Exam vB, PROBLEM 1\n",
    "Maximum Points = 14\n",
    "This problem is about SVD and anomaly detection. In all the problems where you are asked to\n",
    "produce a matrix or vector, they should be numpy arrays.\n",
    "1. [4p] Load the file data/SVD.csv as instructed in the code cell. Compute the Singular Value\n",
    "Decomposition, i.e. construct the three matrices U, D, V such that if X is the data matrix\n",
    "of shape n_samples x n_dimensions then X = UDV^T\n",
    ". Put the resulting matrices in their\n",
    "variables, check that the shapes align with the instructions in the code cell. Finally, extract\n",
    "the first right and left singular vectors and store those as 1-d arrays in the instructed variables.\n",
    "Hint: make sure that the first right and left singular vectors are correct by using\n",
    "the matrix, also be careful about the shape!!\n",
    "2. [3p] The first goal is to calculate the explained variance, check the lecture notes for definition.\n",
    "Calculate the explained variance of using 1, 2,. . . number of singular vectors and select the\n",
    "smallest number of singular vectors that is needed in order to explain at least 90% of the\n",
    "variance.\n",
    "3. [3p] With the number of components chosen in part 2, construct the best approximating\n",
    "matrix with the rank as the number of components. Explain geometrically what each row\n",
    "represents in the approximating matrix in terms of the original data, write your answer as\n",
    "free text in the Markdown cell below as instructed in the cells.\n",
    "4. [4p] Create a vector which corresponds to the row-wise (Euclidean) distance between the\n",
    "original matrix problem1_dataand the approximating matrix problem1_approximation and\n",
    "plot the empirical distribution function of that distance. Based on the empirical distribution\n",
    "function choose a threshold such that 10 samples are above it and the rest below. Store the\n",
    "10 samples in the instructed variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: 4 points\n",
    "# Load the data from the file data/SVD.csv and store the data in a numpy, array called problem1_data below\n",
    "# Double check that the numbers have been parsed correctly by checking the, dtype of the array by calling problem1_data.dtype\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "problem1_data = np.loadtxt(\"data/SVD.csv\", delimiter=\",\")\n",
    "\n",
    "# Check dtype\n",
    "problem1_data.dtype # A numpy array of shape n_samples x n_dimensions\n",
    "# Compute SVD\n",
    "# full_matrices=False ensures correct shapes\n",
    "problem1_U, singular_values, Vt = np.linalg.svd(problem1_data, full_matrices=False)\n",
    "\n",
    "problem1_D = singular_values                     # shape (n_dimensions,)\n",
    "problem1_V = Vt.T                                # shape (n_dimensions, n_dimensions)\n",
    " # The matrix of left singular vectors of problem1_data with,shape n_samples x n_dimensions\n",
    " # The vector of singular values of problem1_data with shape, n_dimensions\n",
    " # The matrix of right singular vectors of problem1_data,with shape n_dimensions x n_dimensions\n",
    "# First singular vectors (1D arrays)\n",
    "problem1_first_right_singular_vector = problem1_V[:, 0].flatten()\n",
    "problem1_first_left_singular_vector = problem1_U[:, 0].flatten()\n",
    " # The first right singular vector,of problem1_data with shape (n_dimensions,) \n",
    "# hint sometimes one needs to invoke,flatten() to avoid having shape (n_dimensions, 1) or (1, n_dimensions)\n",
    " # The first left singular vector, of problem1_data with shape (n_samples,) hint sometimes one needs to invoke, \n",
    "# flatten() to avoid having shape (n_samples, 1) or (1, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: 3 points\n",
    "# Calculate the explained variance of using 1,2,3,...,n_dimensions singular\n",
    "# values and store it as a numpy array called problem1_explained_variance below\n",
    "# Explained variance\n",
    "singular_values_squared = problem1_D ** 2\n",
    "total_variance = np.sum(singular_values_squared)\n",
    "\n",
    "problem1_explained_variance = np.cumsum(singular_values_squared) / total_variance\n",
    " # A numpy array of shape (n_dimensions,),\n",
    "# it should be an increasing sequence of positive numbers and the last element\n",
    "# should be 1\n",
    "# Store in the variable below the smallest number of singular values needed\n",
    "# to explain at least 90% of the variance\n",
    "# Smallest number of components explaining at least 90% variance\n",
    "problem1_num_components = np.argmax(problem1_explained_variance >= 0.9) + 1\n",
    " # An integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e74a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: 3 points\n",
    "# Calculate the approximating matrix of problem1_data using the first\n",
    "# problem1_num_components singular values and store it in the variable below\n",
    "k = problem1_num_components\n",
    "\n",
    "U_k = problem1_U[:, :k]\n",
    "D_k = np.diag(problem1_D[:k])\n",
    "V_k = problem1_V[:, :k]\n",
    "\n",
    "problem1_approximation = U_k @ D_k @ V_k.T # A numpy array of shape n_samples x n_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca9653",
   "metadata": {},
   "source": [
    "1.7 Free text answer\n",
    "Put the explanation for part 3 of the rows of the approximating matrix below this line in this cell.\n",
    "In order to enter edit mode you can doubleclick this cell or select it and just press enter.\n",
    "\n",
    "Each row of the approximating matrix represents the projection of the original data point onto the subspace spanned by the first k right singular vectors. Geometrically, this corresponds to expressing each data point using the k principal directions that capture the most variance, and reconstructing it back in the original space with minimal squared error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85106d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: 4 points\n",
    "# Calculate the reconstruction error of problem1_data using\n",
    "# problem1_approximation and store it in the variable below (should have shape\n",
    "# (n_samples,)) (row wise Euclidean distance)\n",
    "# Row-wise Euclidean reconstruction error\n",
    "problem1_reconstruction_error = np.linalg.norm(\n",
    "    problem1_data - problem1_approximation,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Put the code below to plot the empirical distribution function of the reconstruction error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sorted_errors = np.sort(problem1_reconstruction_error)\n",
    "edf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(sorted_errors, edf)\n",
    "plt.xlabel(\"Reconstruction Error\")\n",
    "plt.ylabel(\"Empirical Distribution Function\")\n",
    "plt.show()\n",
    "\n",
    "# Store the value of the selected threshold in the variable below\n",
    "# Threshold so exactly 10 samples are above it\n",
    "problem1_threshold = np.sort(problem1_reconstruction_error)[-10]\n",
    "\n",
    "# Finally store the samples of problem1_data that have a reconstruction error larger than problem1_threshold in the variable below, should have shape (10, n_dimensions)\n",
    "problem1_outliers = problem1_data[\n",
    "    problem1_reconstruction_error > problem1_threshold\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f3a079",
   "metadata": {},
   "source": [
    "1.8 Exam vB, PROBLEM 2\n",
    "Maximum Points = 13\n",
    "You are given the data-science job salaries dataset found in data/salaries.csv, which contains\n",
    "the salaries of jobs, their experience level and how much of the working hours are remote. Your\n",
    "task is to train a linear regression model to predict the salary of a job based on its attributes:\n",
    "* work_year, The year the salary was paid. * experience_level, The experience level in the job\n",
    "during the year with the following possible values: 0 Entry-level / Junior 1 Mid-level / Intermediate\n",
    "2 Senior-level / Expert 3 Executive-level * employment_type, The type of employement for the role:\n",
    "Part-time, Full-time, Contract, Freelance * salary_in_usd, The total gross salary amount paid in\n",
    "US Dollars. * remote_ratio, The overall amount of work done remotely, possible values are as\n",
    "follows: 0 No remote work (less than 20%) 50 Partially remote 100 Fully remote (more than 80%)\n",
    "To evaluate your model, you will split the dataset into a training set and a testing set. You will use\n",
    "the training set to train your model, and the testing set to evaluate its performance.\n",
    "1. Load the data into a pandas dataframe problem2_df. Based on the column names, figure out\n",
    "what are the features and the target and fill in the answer in the correct cell below. [2p]\n",
    "2. Split the data into train and test. [2p]\n",
    "3. Train the model. [1p]\n",
    "4. On the test set, evaluate the model by computing the mean absolute relative error and plot\n",
    "the empirical distribution function of the residual with confidence bands (i.e. using the DKW\n",
    "inequality and 99% confidence). Hint: you can use the function plotEDF,makeEDF combo\n",
    "from Utils.py that we have used numerous times, which also contains the option to have\n",
    "confidence bands. [3p]\n",
    "$$Absolute\\_relative\\_error = \\left|\\frac{true\\_predicted}{true}\\right|$$\n",
    "5. Provide a scatter plot where the x-axis corresponds to the predicted value and the y-axis is\n",
    "the true value, do this over the test set. [2p]\n",
    "6. Reason about the performance, for instance, is the value of the mean absolute relative error\n",
    "good/bad and what do you think about the scatter plot in point 5? [3p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Let problem2_df be the pandas dataframe that contains the data from the\n",
    "# data/salaries.csv file\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "problem2_df = pd.read_csv(\"data/salaries.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a395a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Fill in the features as a list of strings of the names of the columns\n",
    "problem2_features = [\n",
    "    \"work_year\",\n",
    "    \"experience_level\",\n",
    "    \"employment_type\",\n",
    "    \"remote_ratio\"\n",
    "]\n",
    "\n",
    "problem2_target = \"salary_in_usd\"\n",
    "\n",
    "# Fill in the target as a string with the correct column name\n",
    "'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "# Split the data into train and test using train_test_split\n",
    "# keep the train size as 0.8 and use random_state=42\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = problem2_df[problem2_features]\n",
    "y = problem2_df[problem2_target]\n",
    "\n",
    "problem2_X_train, problem2_X_test, problem2_y_train, problem2_y_test = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "# Include the necessary imports\n",
    "# Initialize your linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "problem2_model = LinearRegression()\n",
    "\n",
    "problem2_model.fit(problem2_X_train, problem2_y_train)\n",
    "\n",
    "# Train your model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4863ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Evaluate the model by computing the mean absolute relative error\n",
    "import numpy as np\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = problem2_model.predict(problem2_X_test)\n",
    "\n",
    "# Absolute Relative Error\n",
    "absolute_relative_error = np.abs((problem2_y_test - y_pred) / problem2_y_test)\n",
    "\n",
    "problem2_mare = np.mean(absolute_relative_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72efc3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Write the code to plot the empirical distribution function of the residual\n",
    "# with confidence bands with 99% confidence in this cell\n",
    "residuals = problem2_y_test - y_pred\n",
    "from Utils import makeEDF, plotEDF\n",
    "\n",
    "edf_x, edf_y = makeEDF(residuals)\n",
    "\n",
    "plotEDF(\n",
    "    edf_x,\n",
    "    edf_y,\n",
    "    confidence=True,\n",
    "    alpha=0.01  # 99% confidence\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d75bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "# Write the code below to produce the scatter plot for part 5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, problem2_y_test)\n",
    "plt.xlabel(\"Predicted Salary (USD)\")\n",
    "plt.ylabel(\"True Salary (USD)\")\n",
    "plt.plot(\n",
    "    [problem2_y_test.min(), problem2_y_test.max()],\n",
    "    [problem2_y_test.min(), problem2_y_test.max()]\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d641a27",
   "metadata": {},
   "source": [
    "1.9 Part 6\n",
    "Double click this cell to enter edit mode and write your answer for part 6 below this line.¬®\n",
    "\n",
    "Discussion on the value of the MARE\n",
    "\n",
    "The mean absolute relative error (MARE) measures the average relative deviation between the predicted and true salaries. A lower MARE indicates better predictive performance. In salary prediction problems, a relatively high MARE is common due to large variance in salaries and unobserved factors such as company size, location, and specific role responsibilities. If the MARE is significantly above, for example, 20‚Äì30%, this suggests that a linear model may be too simplistic for this task.\n",
    "\n",
    "Discussion on the predicted vs. true scatterplot\n",
    "\n",
    "The scatter plot shows how close the predicted salaries are to the true salaries. Ideally, the points should lie close to the diagonal line. A wide spread around the diagonal indicates large prediction errors, especially for high-paying jobs. Systematic deviations (e.g. underestimating high salaries) suggest model bias and limitations of linear regression.\n",
    "\n",
    "Discussion\n",
    "\n",
    "Overall, the linear regression model captures some global trends in the data but struggles to accurately predict individual salaries. This is expected due to the complexity of salary determination and the categorical nature of some variables. More advanced models (e.g. regularized regression, tree-based models, or proper encoding of categorical variables) would likely improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee80d6",
   "metadata": {},
   "source": [
    "1.10 Exam vB, PROBLEM 3\n",
    "Maximum Points = 13\n",
    "Consider the following two Markov chains:\n",
    "\n",
    "Markov Chain A: A to D: 0.8, D to C: 0.5, C to B: 1, B to A: 0, A to B: 0.2, B to C: 1, C to D 0, D to A: 0.5\n",
    "\n",
    "Markov Chain B: A to B: 1, B to C 1, C to B: 0.5, C to D: 0.5, D to C: 0.5, D to E: 0.5, E to F: 1, F to E: 0.5, F to A: 0.5\n",
    "\n",
    "Answer each question for all chains:\n",
    "1. [2p] What is the transition matrix?\n",
    "2. [1p] Is the Markov chain irreducible?\n",
    "3. [4p] Is the Markov chain aperiodic? What is the period for each state? Hint: Recall our definition of period; Let $T := \\{t ‚àà N : P^t(x, x) > 0\\}$ and the greatest common divisor of T is the period.\n",
    "4. [2p] Being in state A at time 0 what is the probability of being in state B at time 5 (after 5 steps)\n",
    "5. [4p] Define T as the first time being in state D starting in state A. That is, if X_0, X_1, . . . is the Markov chain then define for X_0 = ‚ÄùA‚Äù\n",
    "$$T(œâ) = inf_{t‚ààN}\\{t : X_t(œâ) = ‚ÄùD‚Äù\\}$$\n",
    "where the infimum over the empty set is ‚àû. Calculate P(T = 1), P(T = 2), P(T = 3),P(T = 4), P(T = 5), P(T = ‚àû).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66538270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1\n",
    "#------------------------TRANSITION MATRIX -------------------------------\n",
    "# Answer each one by supplying the transition matrix as a numpy array\n",
    "# of shape (n_states,n_states), where state (A,B,...) corresponds to index (0,1,...)\n",
    "import numpy as np\n",
    "\n",
    "problem3_A = np.array([\n",
    "    [0.0, 0.2, 0.0, 0.8],  # A\n",
    "    [0.0, 0.0, 1.0, 0.0],  # B\n",
    "    [0.0, 1.0, 0.0, 0.0],  # C\n",
    "    [0.5, 0.0, 0.5, 0.0]   # D\n",
    "])\n",
    "\n",
    "problem3_B = np.array([\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],  # A\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],  # B\n",
    "    [0.0, 0.5, 0.0, 0.5, 0.0, 0.0],  # C\n",
    "    [0.0, 0.0, 0.5, 0.0, 0.5, 0.0],  # D\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],  # E\n",
    "    [0.5, 0.0, 0.0, 0.0, 0.5, 0.0]   # F\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60deb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2\n",
    "#------------------------REDUCIBLE -------------------------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "# A chain is irreducible if every state can reach every other state.\n",
    "\n",
    "#Chain A: All states communicate (A‚ÜîD‚ÜîC‚ÜîB)\n",
    "\n",
    "#Chain B: All states communicate via cycles including A\n",
    "problem3_A_irreducible = True\n",
    "problem3_B_irreducible = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c32c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3\n",
    "#------------------------APERIODIC-------------------------------\n",
    "\n",
    "#üîπ Chain A\n",
    "\n",
    "#B ‚Üî C forms a 2-cycle\n",
    "\n",
    "#No self-loops\n",
    "\n",
    "#Returns to any state only at even times\n",
    "\n",
    "#‚û° Period = 2 for all states\n",
    "\n",
    "#üîπ Chain B\n",
    "\n",
    "#There are cycles of different lengths\n",
    "\n",
    "#Example:\n",
    "\n",
    "#A ‚Üí B ‚Üí C ‚Üí B ‚Üí ‚Ä¶ (length 2)\n",
    "\n",
    "#A ‚Üí ‚Ä¶ ‚Üí F ‚Üí A (length 5)\n",
    "\n",
    "#gcd(2,5)=1\n",
    "\n",
    "#‚û° All states are aperiodic (period = 1)\n",
    "\n",
    "# Answer each one with a True or False\n",
    "problem3_A_is_aperiodic = False\n",
    "\n",
    "problem3_B_is_aperiodic = True\n",
    "# Answer the following with the period of the states as a numpy array\n",
    "# of shape (n_states,)\n",
    "problem3_A_periods = np.array([2, 2, 2, 2])\n",
    "problem3_B_periods = np.array([1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4\n",
    "# Answer the following with the probability of being in state B at time 5\n",
    "# for the two problems\n",
    "\n",
    "problem3_A_PB5 = 0.0\n",
    "problem3_B_PB5 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d235fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 5\n",
    "# Answer the following probabilities for T=1,2,3,4,5 and infinity\n",
    "problem3_A_PT1 = 0.8\n",
    "problem3_A_PT2 = 0.0\n",
    "problem3_A_PT3 = 0.0\n",
    "problem3_A_PT4 = 0.0\n",
    "problem3_A_PT5 = 0.0\n",
    "problem3_A_PT_inf = 0.0\n",
    "problem3_B_PT1 = 0.0\n",
    "problem3_B_PT2 = 0.0\n",
    "problem3_B_PT3 = 0.5\n",
    "problem3_B_PT4 = 0.0\n",
    "problem3_B_PT5 = 0.25\n",
    "problem3_B_PT_inf = 0.25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
