{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc3abea",
   "metadata": {},
   "source": [
    "1.6 Exam vB, PROBLEM 1\n",
    "Maximum Points = 14\n",
    "A courier company operates a fleet of delivery trucks that make deliveries to different parts of the\n",
    "city. The trucks are equipped with GPS tracking devices that record the location of each truck\n",
    "at regular intervals. The locations are divided into three regions: downtown, the suburbs, and\n",
    "the countryside. The following table shows the probabilities of a truck transitioning between these\n",
    "regions at each time step:\n",
    "\n",
    "| Current region | Probability of transitioning to downtown | Probability of transitioning to the suburbs | Probability of transitioning to the countryside |\n",
    "|---------------|-------------------------------------------|---------------------------------------------|-------------------------------------------------|\n",
    "| Downtown      | 0.3                                       | 0.7                                         | 0                                               |\n",
    "| Suburbs       | 0.2                                       | 0.5                                         | 0.3                                             |\n",
    "| Countryside   | 0                                         | 0.5                                         | 0.5                                             |\n",
    "\n",
    "1. If a truck is currently in the downtown, what is the probability that it will be in the countryside\n",
    "region after 10 time steps? [2p]\n",
    "2. If a truck is currently in the downtown, what is the probability that it will be in the countryside\n",
    "region the first time after three time steps or more? [2p]\n",
    "3. Is this Markov chain irreducible? Explain your answer. [3p]\n",
    "4. What is the stationary distribution? [3p]\n",
    "5. Advanced question: What is the expected number of steps it takes starting from the Downtown region to first reach the Countryside region and then returning to Downtown. Hint: to\n",
    "get within 1 decimal point, it is enough to compute the probabilities for hitting times below\n",
    "120. Motivate your answer in detail [4p]. You could also solve this question by simulation,\n",
    "but this gives you a maximum of [2p].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66e1ac",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Problem 1 – Markov Chain Solutions\n",
    "\n",
    "We are given the **transition matrix** $P$:\n",
    "\n",
    "$$\n",
    "P = \n",
    "\\begin{bmatrix}\n",
    "0.3 & 0.7 & 0 \\\\\n",
    "0.2 & 0.5 & 0.3 \\\\\n",
    "0 & 0.5 & 0.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where the rows/columns correspond to `[Downtown, Suburbs, Countryside]`.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Probability of being in the countryside after 10 steps\n",
    "\n",
    "Let the initial state vector be:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_0 = [1, 0, 0]\n",
    "$$\n",
    "\n",
    "The probability after 10 steps is:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_{10} = \\mathbf{v}_0 P^{10}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Probability of first reaching the countryside after ≥3 steps\n",
    "\n",
    "- Step 1: $P(D \\to C) = 0$  \n",
    "- Step 2: $P(D \\to S \\to C) = 0.7 * 0.3 = 0.21$  \n",
    "\n",
    "$$\n",
    "\\Pr(\\text{first reach ≥3 steps}) = 1 - 0.21 = 0.79\n",
    "$$\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "```python\n",
    "problem1_p2 = 0.79\n",
    "\n",
    "## Part 4: Stationary Distribution\n",
    "\n",
    "We want to solve the stationary distribution $\\pi$ such that:\n",
    "\n",
    "$$\n",
    "\\pi P = \\pi \\quad \\text{and} \\quad \\pi_D + \\pi_S + \\pi_C = 1\n",
    "$$\n",
    "\n",
    "Step 1: Solve for $\\pi_S$ in terms of $\\pi_D$ using the first equation:\n",
    "\n",
    "$$\n",
    "\\pi_D = 0.3 \\pi_D + 0.2 \\pi_S \\implies \\pi_S = 3.5 \\pi_D\n",
    "$$\n",
    "\n",
    "Step 2: Solve for $\\pi_C$ in terms of $\\pi_S$ using the third equation:\n",
    "\n",
    "$$\n",
    "\\pi_C = 0.3 \\pi_S + 0.5 \\pi_C \\implies \\pi_C = 0.6 \\pi_S\n",
    "$$\n",
    "\n",
    "Step 3: Use the normalization condition $\\pi_D + \\pi_S + \\pi_C = 1$ to find $\\pi_D$:\n",
    "\n",
    "$$\n",
    "\\pi_D + \\pi_S + \\pi_C = \\pi_D + 3.5 \\pi_D + 0.6 \\cdot 3.5 \\pi_D = 6.6 \\pi_D = 1 \\implies \\pi_D \\approx 0.152\n",
    "$$\n",
    "\n",
    "Step 4: Compute the remaining components:\n",
    "\n",
    "$$\n",
    "\\pi_S \\approx 0.530, \\quad \\pi_C \\approx 0.318\n",
    "$$\n",
    "\n",
    "**Answer in Python:**\n",
    "\n",
    "```python\n",
    "problem1_stationary = [0.152, 0.530, 0.318]\n",
    "\n",
    "\n",
    "## Part 5: Expected Number of Steps D → C → D\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "E[D \\to C] = x_D, \\quad E[S \\to C] = x_S, \\quad E[C \\to C] = 0\n",
    "$$\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\n",
    "x_S = 1 + 0.2 x_D + 0.5 x_S \\implies x_S = 2 + 0.4 x_D\n",
    "$$  \n",
    "\n",
    "$$\n",
    "x_D = 1 + 0.3 x_D + 0.7 x_S \\implies x_D \\approx 5.714\n",
    "$$  \n",
    "\n",
    "$$\n",
    "x_S \\approx 4.286\n",
    "$$\n",
    "\n",
    "Next, let:\n",
    "\n",
    "$$\n",
    "E[C \\to D] = y_C, \\quad E[S \\to D] = y_S, \\quad E[D \\to D] = 0\n",
    "$$\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\n",
    "y_S = 1 + 0.5 y_S + 0.3 (2 + y_S) \\implies y_S = 8\n",
    "$$  \n",
    "\n",
    "$$\n",
    "y_C = 2 + y_S = 10\n",
    "$$\n",
    "\n",
    "**Total expected steps:**\n",
    "\n",
    "$$\n",
    "E[D \\to C \\to D] = 5.714 + 10 \\approx 15.7\n",
    "$$\n",
    "\n",
    "```python\n",
    "problem1_ET = 15.7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e0751",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Part 1\n",
    "# Fill in the answer to part 1 below\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "P = np.array([[0.3, 0.7, 0],\n",
    "              [0.2, 0.5, 0.3],\n",
    "              [0, 0.5, 0.5]])\n",
    "\n",
    "v0 = np.array([1, 0, 0])\n",
    "v10 = v0 @ np.linalg.matrix_power(P, 10)\n",
    "v10[2]\n",
    "\n",
    "# Part 1\n",
    "problem1_p1 = 0.324\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d37223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "# Fill in the answer to part 2 below\n",
    "# Part 2\n",
    "problem1_p2 = 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ff7f4",
   "metadata": {},
   "source": [
    "1.7 Part 3\n",
    "Double click this cell to enter edit mode and write your answer for part 3 below this line\n",
    "Part 3: Is the Markov chain irreducible?\n",
    "\n",
    "A chain is irreducible if every state can be reached from every other state.\n",
    "\n",
    "Check connectivity:\n",
    "\n",
    "Downtown → Countryside: Need to go through Suburbs → possible. ✅\n",
    "\n",
    "Countryside → Downtown: Countryside → Suburbs → Downtown ✅\n",
    "\n",
    "All states communicate with each other.\n",
    "\n",
    "✅ So the chain is irreducible:\n",
    "\n",
    "problem1_irreducible=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872821cc",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Part 3\n",
    "# Fill in the answer to part 3 below as a boolean\n",
    "problem1_irreducible = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Fill in the answer to part 4 below\n",
    "# the answer should be a numpy array of length 3\n",
    "# make sure that the entries sums to 1!\n",
    "import numpy as np\n",
    "problem1_stationary = np.array([0.152, 0.530, 0.318])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6f24a",
   "metadata": {},
   "source": [
    "1.8 Part 5\n",
    "Double click this cell to enter edit mode and write your answer for part 5 below this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "# Fill in the answer to part 5 below\n",
    "# That is, the expected number of steps\n",
    "problem1_ET = 15.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c6c9d",
   "metadata": {},
   "source": [
    "1.9 Exam vB, PROBLEM 2\n",
    "Maximum Points = 13\n",
    "You are given a “Data Science Salaries” dataset found in data/salaries.csv, which contains\n",
    "employment information of data scientists up to 2023 and the salary obtained. Your task is to\n",
    "train a linear regression model to predict the salary of a data scientist based on the employment\n",
    "information.\n",
    "To evaluate your model, you will split the dataset into a training set and a testing set. You will\n",
    "use the training set to train your model, and the testing set to evaluate its performance.\n",
    "Experience level: 0 = Entry Level, 1 = Mid Level, 2 = Senior Level, 3 = Executive Level.\n",
    "Employment type: 0 = Part Time, 1 = Full Time, 2 = Contractor, 3 = Freelancer\n",
    "1. Load the data into a pandas dataframe problem2_df. Based on the column names, figure\n",
    "out what are the features and the target and fill in the answer in the correct cell below. [1p]\n",
    "2. Split the data into train and test. [1p]\n",
    "3. Train the model. [1p]\n",
    "4. Come up with a reasonable metric and compute it. Provide plots that show the performance\n",
    "of the model. Reason about the performance. [4p]\n",
    "5. Predict the 2023 salary of a data scientist that works full time (1) at mid employment level\n",
    "(1) with 0 remote ratio. Then, looking at the output of problem2_model.coef_, which are\n",
    "the coefficients of the linear model, would a higher remote ratio result in a higher predicted\n",
    "salary or vice versa? [3p]\n",
    "6. Advanced question: On the test set, plot the empirical distribution function of the residual\n",
    "with confidence bands (i.e. using the DKW inequality and 95% confidence). What does the\n",
    "confidence band tell us? What can the confidence band be used for? [3p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Let problem2_df be the pandas dataframe that contains the data from the file\n",
    "# data/abalone.csv\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "problem2_df = pd.read_csv(\"data/salaries.csv\")\n",
    "\n",
    "# Inspect first few rows\n",
    "problem2_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ee4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Fill in the features as a list of strings of the names of the columns\n",
    "problem2_features = [\"XXX\"]\n",
    "# Fill in the target as a string with the correct column name\n",
    "problem2_target = \"XXX\"\n",
    "problem2_features = [\"experience_level\", \"employment_type\", \"remote_ratio\"]\n",
    "problem2_target = \"salary\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9992f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "# Split the data into train and test using train_test_split\n",
    "# keep the train size as 0.8 and use random_state=42\n",
    "problem2_X_train,problem2_X_test,problem2_y_train,problem2_y_test = XXX\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = problem2_df[problem2_features]\n",
    "y = problem2_df[problem2_target]\n",
    "\n",
    "problem2_X_train, problem2_X_test, problem2_y_train, problem2_y_test = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "# Include the necessary imports\n",
    "# Initialize your linear regression model\n",
    "problem2_model = XXX\n",
    "# Train your model on the training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "problem2_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "problem2_model.fit(problem2_X_train, problem2_y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bed49a",
   "metadata": {},
   "source": [
    "1.10 Part 4\n",
    "Double click this cell to enter edit mode and write your answer for part 4 below this line.\n",
    "\n",
    "Reasoning about performance:\n",
    "\n",
    "If points in the predicted vs actual plot are close to the diagonal line → good model fit.\n",
    "\n",
    "Residual plot should have no clear pattern and be roughly centered at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Write the code to diagnose your model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predictions\n",
    "y_pred = problem2_model.predict(problem2_X_test)\n",
    "\n",
    "# Compute metrics\n",
    "rmse = np.sqrt(mean_squared_error(problem2_y_test, y_pred))\n",
    "r2 = r2_score(problem2_y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.2f}\")\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(problem2_y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "plt.xlabel(\"Actual Salary\")\n",
    "plt.ylabel(\"Predicted Salary\")\n",
    "plt.title(\"Predicted vs Actual Salary\")\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "residuals = problem2_y_test - y_pred\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Predicted Salary\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33bf5d",
   "metadata": {},
   "source": [
    "1.11 Part 5\n",
    "Double click this cell to enter edit mode and write your answer for part 5 below this line.\n",
    "\n",
    "If the coefficient for remote_ratio is positive → higher remote ratio → higher salary.\n",
    "\n",
    "If negative → higher remote ratio → lower salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "# Put the code for part 5 below this line\n",
    "\n",
    "# New data point\n",
    "new_data = pd.DataFrame({\n",
    "    \"experience_level\": [1],\n",
    "    \"employment_type\": [1],\n",
    "    \"remote_ratio\": [0]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "problem2_predicted_salary = problem2_model.predict(new_data)[0]\n",
    "print(f\"Predicted salary: {problem2_predicted_salary:.2f}\")\n",
    "\n",
    "print(\"Coefficients:\", problem2_model.coef_)\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": problem2_features,\n",
    "    \"coefficient\": problem2_model.coef_\n",
    "})\n",
    "print(coef_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11e9de7",
   "metadata": {},
   "source": [
    "1.12 Part 6\n",
    "Double click this cell to enter edit mode and write your answer for part 6 below this line.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "The confidence band shows the range in which the true CDF lies with 95% probability.\n",
    "\n",
    "Can be used to assess model residuals, test normality, or validate assumptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c00158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6\n",
    "# Put the code for part 6 below this line\n",
    "\n",
    "# Compute ECDF\n",
    "residuals_sorted = np.sort(residuals)\n",
    "n = len(residuals_sorted)\n",
    "ecdf = np.arange(1, n+1) / n\n",
    "\n",
    "# DKW confidence bands\n",
    "alpha = 0.05\n",
    "epsilon = np.sqrt(np.log(2/alpha)/(2*n))\n",
    "lower = np.maximum(ecdf - epsilon, 0)\n",
    "upper = np.minimum(ecdf + epsilon, 1)\n",
    "\n",
    "# Plot ECDF with confidence bands\n",
    "plt.step(residuals_sorted, ecdf, where='post', label='ECDF')\n",
    "plt.step(residuals_sorted, lower, color='red', linestyle='--', label='95% CI lower')\n",
    "plt.step(residuals_sorted, upper, color='red', linestyle='--', label='95% CI upper')\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.title(\"Empirical CDF of Residuals with 95% Confidence Band\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3226d7",
   "metadata": {},
   "source": [
    "1.13 Exam vB, PROBLEM 3\n",
    "Maximum Points = 13\n",
    "For this problem we have the Diabetes dataset, I have encoded the categorical features\n",
    "using One-Hot encoding, namely the following ['smoking_No Info', 'smoking_current',\n",
    "'smoking_ever', 'smoking_former', 'smoking_never', 'smoking_not current',\n",
    "'sex_Female', 'sex_Male', 'sex_Other'].\n",
    "Treating this as a classification problem, we will train a logistic regression model to predict whether\n",
    "the patient has diabetes or not. Then the task is to evaluate the model and using it to make some\n",
    "conclusions.\n",
    "Instructions:\n",
    "1. Load the file data/diabetes.csv into the pandas dataframe problem3_df. Decide what\n",
    "should be features and target, give motivations for your choices. [3p]\n",
    "2. Create the problem3_X and the problem3_y as numpy arrays with problem3_X being the\n",
    "features and problem3_y being the target. Do the standard train-test split with 80% training\n",
    "data and 20% testing data. Store these in the variables defined in the cells. [2p]\n",
    "3. Now train a Logistic regression model on the training data. Using\n",
    "sklearn.linear_model.LogisticRegression. Hint: If you use many of the One-Hot\n",
    "encoded features you will probably see a warning about max iterations reached, adjust the\n",
    "hyperparameter C (this is the penalization) when you create your LogisticRegression.[2p]\n",
    "4. Evaluation: Calculate the precision and recall for class 0 and 1 with 95% confidence bounds.\n",
    "Explain their meaning [3p]\n",
    "5. Advanced question: Come up with a way to define the one-hot encoded feature that is most\n",
    "important for the prediction. Motivate your choice. [3p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5c058",
   "metadata": {},
   "source": [
    "1.14 Part 1\n",
    "Double click this cell to enter edit mode and write your answer for part 1 below this line\n",
    "\n",
    "What features are reasonable?\n",
    "\n",
    "In regards to how much data we have, how many features do you think we should aim\n",
    "for?\n",
    "\n",
    "What other features would you like to have used but was not collected?\n",
    "\n",
    "Discussion\n",
    "\n",
    "Reasoning:\n",
    "\n",
    "The dataset is already one-hot encoded for categorical variables like smoking and sex.\n",
    "\n",
    "Reasonable features: all one-hot encoded columns, plus any numeric health indicators if available (BMI, age, blood pressure, etc.)\n",
    "\n",
    "Target: whether the patient has diabetes (0 = no, 1 = yes).\n",
    "\n",
    "Discussion:\n",
    "\n",
    "With one-hot encoding, the number of features grows quickly. Aim for less than ~30–50 features if data is limited to avoid overfitting.\n",
    "\n",
    "Additional useful features not collected might include: family history of diabetes, exercise frequency, diet, cholesterol, HbA1c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31520508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Let problem3_df be the pandas dataframe that contains the data from the file\n",
    "# data/visits_clean.csv\n",
    "# Part 1\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "problem3_df = pd.read_csv(\"data/diabetes.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Fill in the features as a list of strings of the names of the columns\n",
    "problem3_features = [\"XXX\"]\n",
    "# Fill in the target as a string with the correct column name\n",
    "problem3_target = \"XXX\"\n",
    "\n",
    "# Features and target\n",
    "problem3_features = [\n",
    "    'smoking_No Info', 'smoking_current', 'smoking_ever', 'smoking_former',\n",
    "    'smoking_never', 'smoking_not current', 'sex_Female', 'sex_Male', 'sex_Other'\n",
    "]\n",
    "problem3_target = 'diabetes'  # assuming column is named 'diabetes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "# Fill in your X and y below\n",
    "problem3_X = XXX\n",
    "problem3_y = XXX\n",
    "# Split the data into train and test using train_test_split\n",
    "# keep the train size as 0.8 and use random_state=42\n",
    "problem3_X_train, problem3_X_test, problem3_y_train, problem3_y_test = XXX\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and target arrays\n",
    "problem3_X = problem3_df[problem3_features].values\n",
    "problem3_y = problem3_df[problem3_target].values\n",
    "\n",
    "# Train-test split\n",
    "problem3_X_train, problem3_X_test, problem3_y_train, problem3_y_test = train_test_split(\n",
    "    problem3_X, problem3_y, train_size=0.8, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8176eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "# Initialize your LogisticRegression model\n",
    "problem3_model = XXX\n",
    "# Fit your initialized model on the training data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize model with stronger regularization\n",
    "problem3_model = LogisticRegression(max_iter=500, C=1.0)\n",
    "\n",
    "# Fit model\n",
    "problem3_model.fit(problem3_X_train, problem3_y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240c257",
   "metadata": {},
   "source": [
    "1.15 Part 4\n",
    "Double click this cell to enter edit mode and write your answer for part 4 below this line\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "Precision: fraction of predicted positives that are correct.\n",
    "\n",
    "Recall: fraction of true positives that were predicted correctly.\n",
    "\n",
    "Confidence intervals show uncertainty in these metrics due to sample variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "# Give the answer for each of the following quantities in the form of a tuple\n",
    "# Example, if we want to say that the precision for class 0 is between 0.31 and 0.69\n",
    "# then we would answer\n",
    "# problem3_precision_0 = (0.31,0.69)\n",
    "problem3_precision_0 = XXX\n",
    "problem3_recall_0 = XXX\n",
    "problem3_precision_1 = XXX\n",
    "problem3_recall_1 = XXX\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Predictions\n",
    "y_pred = problem3_model.predict(problem3_X_test)\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_boot = 1000\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "precision_0_samples = []\n",
    "recall_0_samples = []\n",
    "precision_1_samples = []\n",
    "recall_1_samples = []\n",
    "\n",
    "for _ in range(n_boot):\n",
    "    idx = rng.choice(len(problem3_y_test), len(problem3_y_test), replace=True)\n",
    "    y_true_sample = problem3_y_test[idx]\n",
    "    y_pred_sample = y_pred[idx]\n",
    "    \n",
    "    precision_0_samples.append(precision_score(y_true_sample, y_pred_sample, pos_label=0))\n",
    "    recall_0_samples.append(recall_score(y_true_sample, y_pred_sample, pos_label=0))\n",
    "    precision_1_samples.append(precision_score(y_true_sample, y_pred_sample, pos_label=1))\n",
    "    recall_1_samples.append(recall_score(y_true_sample, y_pred_sample, pos_label=1))\n",
    "\n",
    "# 95% confidence intervals\n",
    "problem3_precision_0 = (np.percentile(precision_0_samples, 2.5), np.percentile(precision_0_samples, 97.5))\n",
    "problem3_recall_0 = (np.percentile(recall_0_samples, 2.5), np.percentile(recall_0_samples, 97.5))\n",
    "problem3_precision_1 = (np.percentile(precision_1_samples, 2.5), np.percentile(precision_1_samples, 97.5))\n",
    "problem3_recall_1 = (np.percentile(recall_1_samples, 2.5), np.percentile(recall_1_samples, 97.5))\n",
    "\n",
    "print(\"Precision 0:\", problem3_precision_0)\n",
    "print(\"Recall 0:\", problem3_recall_0)\n",
    "print(\"Precision 1:\", problem3_precision_1)\n",
    "print(\"Recall 1:\", problem3_recall_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41235273",
   "metadata": {},
   "source": [
    "1.16 Part 5\n",
    "Double click this cell to enter edit mode and write your answer for part 5 below this line.\n",
    "\n",
    "Motivation:\n",
    "\n",
    "The coefficient directly affects the log-odds of diabetes.\n",
    "\n",
    "One-hot features with the largest positive coefficient → strongly increase predicted probability of diabetes.\n",
    "\n",
    "Largest negative coefficient → strongly decrease predicted probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "# Put whatever calculations you need here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": problem3_features,\n",
    "    \"coefficient\": problem3_model.coef_[0]\n",
    "}).sort_values(by=\"coefficient\", key=abs, ascending=False)\n",
    "\n",
    "# Most important feature\n",
    "most_important_feature = coef_df.iloc[0]\n",
    "print(most_important_feature)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
